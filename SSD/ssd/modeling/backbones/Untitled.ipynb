{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bc582ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple, List\n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abb5e87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet34(pretrained=True)\n",
    "img = torch.zeros((1, 3, 128, 1024))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0d77f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_channels=[128, 256, 128, 128, 64, 64]\n",
    "feature_extractor = nn.Sequential(#sol\n",
    "    nn.Conv2d(3, 32, kernel_size=3, padding=1),#sol\n",
    "    nn.BatchNorm2d(32),#sol\n",
    "    nn.LeakyReLU(0.2),#sol\n",
    "    nn.Conv2d(32, 64, kernel_size=3, padding=1),#sol\n",
    "    nn.BatchNorm2d(64),#sol\n",
    "    nn.LeakyReLU(0.2),#sol\n",
    "    #sol\n",
    "    nn.MaxPool2d(2,2), # 64x512 out#sol\n",
    "    nn.Conv2d(64, 128, kernel_size=3, padding=1),#sol\n",
    "    nn.BatchNorm2d(128),#sol\n",
    "    nn.LeakyReLU(0.2),#sol\n",
    "    nn.Conv2d(128, 128, kernel_size=3, padding=1),#sol\n",
    "    nn.BatchNorm2d(128),#sol\n",
    "    nn.LeakyReLU(0.2),#sol\n",
    "    nn.Conv2d(128, 256, kernel_size=3, padding=1),#sol\n",
    "    nn.BatchNorm2d(256),#sol\n",
    "    nn.LeakyReLU(0.2),#sol\n",
    "    nn.Conv2d(256, 512, kernel_size=3, padding=1),#sol\n",
    "    nn.BatchNorm2d(512),#sol\n",
    "    nn.LeakyReLU(0.2),#sol\n",
    "    #Ouput 32#\n",
    "    nn.Conv2d(512, output_channels[0], kernel_size=3, padding=1,stride=2),#so    \n",
    ") #sol\n",
    "        \n",
    "additional_layers = nn.ModuleList([#sol\n",
    "    nn.Sequential( # 16 x 128 out#sol\n",
    "        nn.BatchNorm2d(output_channels[0]),#sol\n",
    "        nn.LeakyReLU(0.2),#sol\n",
    "        nn.Conv2d(output_channels[0], 512, kernel_size=3, padding=1),#sol\n",
    "        nn.BatchNorm2d(512),#sol\n",
    "        nn.LeakyReLU(0.2),#sol\n",
    "        nn.Conv2d(512, output_channels[1], kernel_size=3, padding=1, stride=2),#sol\n",
    "    ),#sol\n",
    "    nn.Sequential( # 8x64 out#sol\n",
    "        nn.BatchNorm2d(output_channels[1]),#sol\n",
    "        nn.LeakyReLU(0.2),#sol\n",
    "        nn.Conv2d(output_channels[1], 256, kernel_size=3, padding=1),#sol\n",
    "        nn.BatchNorm2d(256),#sol\n",
    "        nn.LeakyReLU(0.2),#sol\n",
    "        nn.Conv2d(256, output_channels[2], kernel_size=3, padding=1, stride=2),#sol\n",
    "    ),#sol\n",
    "    nn.Sequential( # 4 x 32 out#sol\n",
    "        nn.BatchNorm2d(output_channels[2]),#sol\n",
    "        nn.LeakyReLU(0.2),#sol\n",
    "        nn.Conv2d(output_channels[2], 128, kernel_size=3, padding=1),#sol\n",
    "        nn.BatchNorm2d(128),#sol\n",
    "        nn.LeakyReLU(0.2),#sol\n",
    "        nn.Conv2d(128, output_channels[3], kernel_size=3, padding=1, stride=2),#sol\n",
    "    ),#sol\n",
    "    nn.Sequential( # 2 x 16 out#sol\n",
    "        nn.BatchNorm2d(output_channels[3]),#sol\n",
    "        nn.LeakyReLU(0.2),#sol\n",
    "        nn.Conv2d(output_channels[3], 128, kernel_size=3, padding=1),#sol\n",
    "        nn.BatchNorm2d(128),#sol\n",
    "        nn.LeakyReLU(0.2),#sol\n",
    "        nn.Conv2d(128, output_channels[4], kernel_size=3, stride=2, padding=1),#sol\n",
    "    ),#sol\n",
    "    nn.Sequential( # 1 x 8 out#sol\n",
    "        nn.BatchNorm2d(output_channels[4]),#sol\n",
    "        nn.LeakyReLU(0.2),#sol\n",
    "        nn.Conv2d(output_channels[4], 128, kernel_size=2, padding=1),#sol\n",
    "        nn.BatchNorm2d(128),#sol\n",
    "        nn.LeakyReLU(0.2),#sol\n",
    "        nn.Conv2d(128, output_channels[5], kernel_size=2,stride=2),#sol\n",
    "    ),#sol\n",
    "\n",
    "])#sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18f3be26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 128, 1024])\n",
      "torch.Size([1, 128, 32, 256])\n"
     ]
    }
   ],
   "source": [
    "img = torch.zeros((1, 3, 128, 1024))\n",
    "\n",
    "print(img.shape)\n",
    "out_features = []\n",
    "x = feature_extractor(img)#sol\n",
    "out_features.append(x)#sol\n",
    "\n",
    "print(out_features[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b73dccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for additional_layer in additional_layers.children():#sol\n",
    "    x = additional_layer(x)#sol\n",
    "    out_features.append(x)#sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46874067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 32, 256])\n",
      "torch.Size([1, 256, 16, 128])\n",
      "torch.Size([1, 128, 8, 64])\n",
      "torch.Size([1, 128, 4, 32])\n",
      "torch.Size([1, 64, 2, 16])\n",
      "torch.Size([1, 64, 1, 8])\n"
     ]
    }
   ],
   "source": [
    "for i in out_features:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb0a7b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "x = OrderedDict()\n",
    "x['feat0'] = out_features[0]\n",
    "x['feat1'] = out_features[1]\n",
    "x['feat2'] = out_features[2]\n",
    "x['feat3'] = out_features[3]\n",
    "x['feat4'] = out_features[4]\n",
    "x['feat5'] = out_features[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff8ea735",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=torchvision.ops.FeaturePyramidNetwork([128,256,128,128,64,64],256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea94d723",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=torchvision.ops.FeaturePyramidNetwork([10,20,30],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67c6e6a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [5, 30, 1, 1], expected input[1, 64, 1, 8] to have 30 channels, but got 64 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1101737/3600102034.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torchvision/ops/feature_pyramid_network.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mlast_inner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result_from_inner_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result_from_layer_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torchvision/ops/feature_pyramid_network.py\u001b[0m in \u001b[0;36mget_result_from_inner_blocks\u001b[0;34m(self, x, idx)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 443\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    444\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [5, 30, 1, 1], expected input[1, 64, 1, 8] to have 30 channels, but got 64 channels instead"
     ]
    }
   ],
   "source": [
    "out= m(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcfd47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([(k, v.shape) for k, v in out.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6621df17",
   "metadata": {},
   "outputs": [],
   "source": [
    "out['feat0']=(nn.Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))(out['feat0']))\n",
    "out['feat1']=(nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))(out['feat1']))\n",
    "out['feat2']=(nn.Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))(out['feat2']))\n",
    "out['feat3']=(nn.Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))(out['feat3']))\n",
    "out['feat4']=(nn.Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))(out['feat4']))\n",
    "out['feat5']=(nn.Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))(out['feat5']))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18952753",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([(k, v.shape) for k, v in out.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58ac379f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple, List\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "77131f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros((1, 3, 128, 1024))\n",
    "backbone = torchvision.models.resnet34(pretrained=True)\n",
    "base_layer0 = nn.Sequential( backbone.conv1,  backbone.bn1,  backbone.relu,  backbone.maxpool)\n",
    "base_layer1 = nn.Sequential( backbone.layer1,backbone.maxpool)\n",
    "base_layer2 = nn.Sequential( backbone.layer2)\n",
    "base_layer3 = nn.Sequential( backbone.layer3)\n",
    "base_layer4 = nn.Sequential( backbone.layer4)\n",
    "print(backbone.conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b70b596e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024, 1, 8])\n"
     ]
    }
   ],
   "source": [
    "c1 = base_layer0(x)\n",
    "c2 = base_layer1(c1)\n",
    "c3 = base_layer2(c2)\n",
    "c4 = base_layer3(c3)\n",
    "c5 = base_layer4(c4)\n",
    "aux= nn.Conv2d(512, 1024, kernel_size=1, stride=2)\n",
    "c6= aux(c5)\n",
    "c7= nn.Conv2d(1024,1024,kernel_size=1,stride=2)(c6)\n",
    "aux= \n",
    "from collections import OrderedDict\n",
    "x= OrderedDict()\n",
    "x['feat0'] = c2\n",
    "x['feat1'] = c3\n",
    "x['feat2'] = c4\n",
    "x['feat3'] = c5\n",
    "x['feat4'] = c6\n",
    "x['feat5'] = c7\n",
    "\n",
    "m=torchvision.ops.FeaturePyramidNetwork([64,128,256,512,1024],256)\n",
    "out_features = []\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "680e3ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024, 1, 8])\n"
     ]
    }
   ],
   "source": [
    "print(c6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb433d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "out=m(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6943f433",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([(k, v.shape) for k, v in out.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b04f559",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_features=[]\n",
    "for k, v in out.items():\n",
    "    out_features.append(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293815ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e02b82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
